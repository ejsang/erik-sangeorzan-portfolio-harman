{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Erik Sangeorzan: Engineering Portfolio","text":"<p>Welcome to my portfolio. This site showcases selected projects in embedded systems, audio processing, and automotive software engineering.</p>"},{"location":"#featured-projects","title":"Featured Projects","text":"<ul> <li>Real-Time Audio Separation \u2013 Low-latency embedded audio capture and processing with I2S and multitasking</li> <li>Stratum Synthesizer \u2013 Assembly-level audio synthesis engine with bare-metal drivers</li> <li>Toyota Auto-Validation (HARMAN) \u2013 Automated test framework and validation for embedded automotive systems</li> <li>Zumo Shield Robot \u2013 Real-time embedded control with hardware timers and PWM</li> <li>Analyzing Tennis Matches (Audio DSP) \u2013 Signal processing and algorithm prototyping in MATLAB</li> </ul>"},{"location":"#alignment-with-harman-roles","title":"Alignment with HARMAN Roles","text":"<p>See Role Fit for a detailed mapping of project experience to HARMAN's Principal Engineer job requirements (automotive audio systems, embedded DSP, real-time systems, and automotive diagnostics).</p>"},{"location":"#about-me","title":"About Me","text":"<p>I'm an embedded systems engineer with deep experience in audio processing, real-time firmware development, and automotive systems. My work spans low-level hardware drivers, audio signal processing, and system-level validation and testing.</p> <p>View my Resume &amp; Cover Letter or explore individual projects for detailed design notes, code snippets, and results.</p>"},{"location":"DEPLOY/","title":"Deploying this portfolio (GitHub Pages - MkDocs)","text":"<p>This repo contains a GitHub Actions workflow that builds the MkDocs site and deploys to the <code>gh-pages</code> branch automatically on push to <code>main</code> or <code>master</code>.</p>"},{"location":"DEPLOY/#quick-checklist","title":"Quick checklist","text":"<ol> <li>Repository is ready with <code>.github/workflows/deploy.yml</code></li> <li>Default branch is set to <code>main</code></li> <li>GitHub Actions is enabled</li> <li>After the first successful workflow run, the site is published to GitHub Pages</li> </ol>"},{"location":"DEPLOY/#notes","title":"Notes","text":"<ul> <li>The workflow uses <code>GITHUB_TOKEN</code> automatically (no extra secret needed)</li> <li>Site URL: https://ejsang.github.io/erik-sangeorzan-portfolio-harman/</li> </ul>"},{"location":"resume-cover/","title":"Resume &amp; Cover Letter","text":"<p>Last updated: 2026-01-19</p>"},{"location":"resume-cover/#resume","title":"Resume","text":"<p> Open in Google Docs   |   Download PDF </p>"},{"location":"resume-cover/#cover-letter","title":"Cover Letter","text":"<p> Open in Google Docs   |   Download PDF </p>"},{"location":"role-fit/","title":"Role Fit: HARMAN Principal Engineer, Audio Systems","text":"<p>Context: This page maps HARMAN's Principal Engineer requirements to specific project evidence in this portfolio. Each section below corresponds to a key requirement, with links to relevant projects and explanations of how they demonstrate the skill.</p> <p>Professional Experience Note: While this portfolio showcases academic and personal projects, my professional experience at Ford involved rigorous Ethernet/IP/TCP/UDP protocol conformance testing, packet analysis, and the implementation of deterministic CI test harnesses.</p>"},{"location":"role-fit/#design-develop-and-test-embedded-software-and-associated-components-for-audio-products-cc","title":"Design, develop and test embedded software and associated components for audio products (C/C++)","text":"<ul> <li>Real-Time Audio Separation: Teensy firmware, I2S/UART C/C++ code, Raspberry Pi processing and multithreaded Python demos demonstrating low-latency embedded audio capture and processing.</li> <li>Analyzing Tennis Matches Based on Audio: MATLAB-based audio signal processing and algorithm development (transient detection, spectral analysis) relevant to audio product R&amp;D.</li> <li>Stratum Synthesizer: assembly-level audio engine and drivers showing deep knowledge of audio signal path and constraints.</li> </ul>"},{"location":"role-fit/#hardware-drivers-embedded-software-applications-audio-and-control-networking-cc","title":"Hardware drivers, embedded software applications, audio and control networking (C/C++)","text":"<ul> <li>Stratum Synthesizer: speaker and SD drivers, low-level peripheral control.</li> <li>Zumo Shield Robot: STM32 PWM, timers, UART and GPIO; illustrates driver usage and hardware control.</li> </ul>"},{"location":"role-fit/#real-time-multitasking-and-os-concepts-embedded-linux-threads-synchronization","title":"Real-time, multitasking, and OS concepts (Embedded Linux / threads / synchronization)","text":"<ul> <li>Real-Time Audio Separation: Embedded Linux user-space on Raspberry Pi + concurrency + synchronization.</li> <li>Zumo Shield Robot: microcontroller timing/interrupts and real-time control loop design.</li> </ul>"},{"location":"role-fit/#networking-protocols-uart-i2s-possibility-to-work-with-ethernettcpudpwi-fi","title":"Networking &amp; protocols (UART, I2S, possibility to work with Ethernet/TCP/UDP/Wi-Fi)","text":"<ul> <li>Professional: Ethernet/IP/TCP/UDP (protocol conformance + packet analysis) - see resume for Ford experience.</li> <li>Projects: Real-Time Audio Separation: I2S audio capture and UART streaming; demonstrates embedded audio streaming concepts.</li> </ul>"},{"location":"role-fit/#software-architecture-design-and-testing-reviews-unitintegration-tests","title":"Software architecture, design, and testing (reviews, unit/integration tests)","text":"<ul> <li>Toyota Auto-Validation: demonstrates test automation and reporting.</li> <li>Professional: Experience with SonarQube rollout, deterministic builds, and harness-based validation.</li> <li>Process: I prioritize clear documentation, peer reviews, and testability (see reports included with each project).</li> <li>Organization: I estimate, organize, and document tasks as part of the standard engineering workflow.</li> </ul>"},{"location":"role-fit/#hardware-debugging-and-release-processes","title":"Hardware debugging and release processes","text":"<ul> <li>Zumo Shield Robot and Stratum Synthesizer show hardware bring-up, telemetry, and iterative debugging workflows; Toyota demo shows validation and reporting practices.</li> </ul>"},{"location":"role-fit/#version-control-and-documentation","title":"Version control and documentation","text":"<ul> <li>Full repositories and README/USAGE/OVERVIEW docs are included with each project; this portfolio itself is version-controlled and deploy-ready.</li> </ul>"},{"location":"projects/","title":"Projects","text":"<p>Browse the projects below. Each card links to a detailed page with context, design notes, and selected code.</p> <ul> <li>Real-Time Audio Separation of Human Voices: Real-time multitasking audio acquisition (Teensy + Raspberry Pi), I2S, UART, and embedded Linux multiprocessing.</li> <li>Stratum Synthesizer (Assembly): Low-level drivers (speaker, SD, touchscreen) and audio synthesis implemented in assembly for constrained systems.</li> <li>Zumo Shield Robot Navigation (C): Embedded C navigation and control with PWM motor control, hardware timers, and UART telemetry.</li> <li>Toyota Auto-Validation (HARMAN) Demo: Validation and test automation demo for system-level testing and automated reporting.</li> <li>Analyzing Tennis Matches Based on Audio (MATLAB): DSP algorithm prototyping and signal processing.</li> </ul>"},{"location":"projects/real-time-audio-separation/","title":"Real-Time Audio Separation of Human Voices","text":"<p>Summary: Real-time source separation project combining embedded Teensy audio acquisition (I2S), UART streaming, Raspberry Pi multicore processing, and a Python GUI for real-time playback and visualization. Demonstrates embedded audio capture, DSP algorithms, synchronization, and performance engineering.</p> <p>Problem: Build a small-form-factor array to capture and separate human voices in real-time.</p> <p>Approach: Implement low-latency audio capture on Teensy (I2S), transmit via UART to a Raspberry Pi, perform online ICA/FFT-based processing with multiprocessing, and provide a multithreaded Python GUI for playback/visualization.</p> <p>Results: Working demo with real-time playback, written report and poster, performance tradeoffs documented.</p>"},{"location":"projects/real-time-audio-separation/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>C/C++ on embedded platforms (I2S, UART), Python multiprocessing and multithreading</li> <li>Real-time DSP (FFT, ICA), FIR filtering (low-pass)</li> <li>Hardware synchronization using GPIO, performance tuning and profiling</li> </ul>"},{"location":"projects/real-time-audio-separation/#why-this-is-relevant-to-harman","title":"Why this is relevant to HARMAN","text":"<ul> <li>Design/develop/test C/C++ embedded component: Implemented I2S capture and UART streaming firmware.</li> <li>System Integration: Integrated HW/SW system and debugged timing/synchronization issues between microcontroller and processor.</li> <li>Real-time multitasking: Managed multiprocessing/multithreading with strict performance constraints.</li> </ul>"},{"location":"projects/real-time-audio-separation/#how-to-run-reproduce","title":"How to run / reproduce","text":"<p>Hardware:</p> <ul> <li>Teensy boards with Audio Shield (or equivalent), a Raspberry Pi (4 recommended), microphones (or test audio), and a UART connection between Teensy and Pi.</li> </ul> <p>Quick steps:</p> <ul> <li>Run the self-contained demo: open <code>src_computer_runnable_demo/</code> and follow its README.</li> <li>On the Raspberry Pi (or laptop):</li> <li>Create a Python virtualenv and install dependencies: <code>pip install numpy scipy matplotlib pyaudio</code></li> <li>Run:</li> </ul> <pre><code>python3 src/multiproc_cogent.py\npython3 src/ui3_1_maxplayback.py\n</code></pre> <ul> <li>On each Teensy: flash <code>src/valuecheck.ino</code> (use Arduino IDE / Teensy Loader) and set I2S/UART parameters as described in <code>OVERVIEW.txt</code>.</li> </ul>"},{"location":"projects/real-time-audio-separation/#what-id-improve-next","title":"What I'd improve next","text":"<ul> <li>Latency Budget: Quantify and optimize the end-to-end latency budget (currently limited by UART bandwidth).</li> <li>Buffering Strategy: Implement circular buffering to reduce jitter and dropouts.</li> <li>Test Strategy: Add automated regression tests for the DSP blocks.</li> </ul>"},{"location":"projects/real-time-audio-separation/#downloads","title":"Downloads","text":"<ul> <li>Final report (PDF)</li> <li>Slide deck (PDF)</li> <li>Poster (PDF)</li> <li>Demo video (MP4)</li> <li>Runnable demo (zip)</li> </ul>"},{"location":"projects/stratum-synthesizer/","title":"Stratum Synthesizer (Assembly)","text":"<p>Summary: A hand-crafted audio synthesizer implemented largely in assembly with low-level drivers for speaker output, SD card access, SDRAM, and touchscreen I/O - focused on efficiency and driver-level control.</p> <p>Problem: Produce a functional synthesizer on constrained embedded hardware with multiple instrument voices and low-latency control.</p> <p>Approach: Implement synthesis routines and driver code in assembly for tight control over timing and memory; build drivers for SD I/O and speaker output.</p> <p>Results: Full synthesizer with multiple instruments and a touchscreen interface; source demonstrates low-level driver work and audio path implementation.</p>"},{"location":"projects/stratum-synthesizer/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>Assembly-level optimization and hardware driver development</li> <li>Real-time audio signal generation and low-latency control</li> <li>Debugging constrained systems and interfacing with peripherals</li> </ul>"},{"location":"projects/stratum-synthesizer/#why-this-is-relevant-to-harman","title":"Why this is relevant to HARMAN","text":"<ul> <li>Shows low-level embedded audio engineering and driver development experience (Speaker PWM, SD Card SPI, Touchscreen I2C) important for firmware that directly handles audio devices and peripheral interfaces.</li> </ul>"},{"location":"projects/stratum-synthesizer/#driver-interface-sketch","title":"Driver Interface Sketch","text":"<pre><code>// Pseudocode illustrating the driver interface logic implemented in assembly\n// See 'speaker_driver.e' for the actual assembly implementation\n\nvoid Audio_ISR(void) {\n    // 1. Acknowledge Interrupt\n    Clear_IRQ(AUDIO_IRQ_MASK);\n\n    // 2. Check FIFO status\n    if (!FIFO_Full(AUDIO_FIFO_ADDR)) {\n        // 3. Fetch next sample from synthesis engine\n        int16_t sample = Synth_GetNextSample();\n\n        // 4. Write to hardware register\n        Write_Reg(AUDIO_DATA_REG, sample);\n    }\n}\n</code></pre>"},{"location":"projects/tennis-audio-analysis/","title":"Analyzing Tennis Matches Based on Audio (MATLAB)","text":"<p>Summary: A signal processing project using MATLAB to analyze audio from tennis matches to detect ball hits, identify \"out\" calls vs. applause, and track game score automatically.</p> <p>Problem: Automate the tracking of tennis match events and scoring using only audio cues.</p> <p>Approach: Developed MATLAB algorithms to detect transients (ball hits), spectral features for applause vs. net hits, and implemented a state machine to track scoring.</p> <p>Results: Successfully detected ball hits and applause in test clips; identified limitations in net hit detection for specific rallies.</p>"},{"location":"projects/tennis-audio-analysis/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>Audio Signal Processing (MATLAB)</li> <li>Algorithm Development (transient detection, spectral analysis)</li> <li>State Machine Logic for scoring</li> </ul>"},{"location":"projects/tennis-audio-analysis/#why-this-is-relevant-to-harman","title":"Why this is relevant to HARMAN","text":"<ul> <li>Demonstrates fundamental audio signal processing and algorithm development skills using MATLAB (DSP prototyping).</li> </ul>"},{"location":"projects/tennis-audio-analysis/#project-website","title":"Project website","text":"<p>For a detailed breakdown of the methodology and results, visit the project website.</p>"},{"location":"projects/toyota-auto-validation/","title":"Toyota Auto-Validation (HARMAN) Demo","text":"<p>Summary: Automated validation demo for embedded automotive systems, showcasing programmatic control of test equipment and data-driven testing scenarios using C# scripts.</p> <p>Problem: Demonstrate automated validation and reporting for an embedded automotive system.</p> <p>Approach: - Developed C# validation scripts to automate system-level test scenarios. - Implemented programmatic control of lab equipment (function generators) to simulate input signals. - Automated parameter updates for variable test conditions (e.g., specific data sets, frequency response scenarios like <code>DAB Stereo: Speed, -30dB, 80mph</code>).</p> <p>Results: Demo video and notes showcasing test methodology and results.</p>"},{"location":"projects/toyota-auto-validation/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>Test Automation: Equipment control API implementation and test case parameterization.</li> <li>Reporting: Automated generation of validation results and reports.</li> <li>Verification: System-level validation mindset and stakeholder communication.</li> </ul>"},{"location":"projects/toyota-auto-validation/#why-this-is-relevant-to-harman","title":"Why this is relevant to HARMAN","text":"<ul> <li>Directly demonstrates automotive embedded system validation experience for complex system-level testing and verification.</li> <li>Shows ability to design and implement automated test frameworks that scale with product complexity.</li> <li>Illustrates communication of technical validation results to stakeholders and project teams.</li> </ul>"},{"location":"projects/toyota-auto-validation/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Play the demo video below to view the validation walkthrough.</li> </ul>"},{"location":"projects/toyota-auto-validation/#downloads-video","title":"Downloads &amp; video","text":"<ul> <li>Demo video: toyota-demo.mp4</li> <li>Code snippet: validation_snippet.cs (Sample abstraction for equipment control)</li> </ul>"},{"location":"projects/toyota-auto-validation/#what-to-inspect","title":"What to inspect","text":"<ul> <li>Watch the Demo video to see the automated test setup and equipment control in action.</li> <li>Review the Code snippet for an example of the driver/control abstraction used for test automation.</li> </ul>"},{"location":"projects/zumo-shield-robot/","title":"Zumo Shield Robot Navigation (C)","text":"<p>Summary: STM32-based robot navigation project showing motor control, sensor IO, PWM, timers, and UART telemetry using the STM32 HAL and C.</p> <p>Problem: Implement reliable line-following and navigation on a Zumo robot using the STM32 microcontroller.</p> <p>Approach: Use STM32 HAL to manage PWM motor control, GPIO sensors, timers and UART for debug telemetry; implement sensor scanning and corrective control logic in C.</p> <p>Results: Working line-following implementation with telemetry and documented firmware (<code>main.c</code>).</p>"},{"location":"projects/zumo-shield-robot/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>Embedded C programming on STM32 (PWM, timers, UART, GPIO)</li> <li>Low-level hardware control and real-time loop design for control systems</li> <li>Hardware debugging and interfacing with sensors and actuators</li> </ul>"},{"location":"projects/zumo-shield-robot/#why-this-is-relevant-to-harman","title":"Why this is relevant to HARMAN","text":"<ul> <li>Demonstrates embedded firmware development, hardware driver use, and debugging.</li> <li>UART telemetry for debugging and timing/PWM tuning directly maps to device firmware development.</li> </ul>"},{"location":"projects/zumo-shield-robot/#test-procedure","title":"Test Procedure","text":"<ol> <li>Unit Test: Verify individual sensor readings via UART output while manually moving the robot over contrasting surfaces.</li> <li>Integration Test: Tune PID control loop parameters (Kp, Ki, Kd) using real-time telemetry to achieve stable line tracking at increasing speeds.</li> <li>System Validation: Run full course navigation tests to verify corner handling and intersection logic.</li> </ol>"}]}