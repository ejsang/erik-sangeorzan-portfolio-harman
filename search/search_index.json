{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Erik Sangeorzan: Engineering Portfolio","text":"<p>Welcome to my portfolio. This site showcases selected projects in embedded systems, audio processing, and automotive software engineering.</p>"},{"location":"#featured-projects","title":"Featured Projects","text":"<ul> <li>Real-Time Audio Separation \u2013 Low-latency embedded audio capture and processing with I2S and multitasking</li> <li>Stratum Synthesizer \u2013 Assembly-level audio synthesis engine with bare-metal drivers</li> <li>Toyota Auto-Validation (HARMAN) \u2013 Automated test framework and validation for embedded automotive systems</li> <li>Zumo Shield Robot \u2013 Real-time embedded control with hardware timers and PWM</li> <li>Analyzing Tennis Matches (Audio DSP) \u2013 Signal processing and algorithm prototyping in MATLAB</li> </ul>"},{"location":"#alignment-with-harman-roles","title":"Alignment with HARMAN Roles","text":"<p>See Role Fit for a detailed mapping of project experience to HARMAN's Principal Engineer job requirements (automotive audio systems, embedded DSP, real-time systems, and automotive diagnostics).</p>"},{"location":"#about-me","title":"About Me","text":"<p>I'm an embedded systems engineer with deep experience in audio processing, real-time firmware development, and automotive systems. My work spans low-level hardware drivers, audio signal processing, and system-level validation and testing.</p> <p>View my Resume &amp; Cover Letter or explore individual projects for detailed design notes, code snippets, and results.</p>"},{"location":"DEPLOY/","title":"Deploying this portfolio (GitHub Pages - MkDocs)","text":"<p>This repo contains a GitHub Actions workflow that builds the MkDocs site and deploys to the <code>gh-pages</code> branch automatically on push to <code>main</code> or <code>master</code>.</p>"},{"location":"DEPLOY/#quick-checklist","title":"Quick checklist","text":"<ol> <li>Repository is ready with <code>.github/workflows/deploy.yml</code></li> <li>Default branch is set to <code>main</code></li> <li>GitHub Actions is enabled</li> <li>After the first successful workflow run, the site is published to GitHub Pages</li> </ol>"},{"location":"DEPLOY/#notes","title":"Notes","text":"<ul> <li>The workflow uses <code>GITHUB_TOKEN</code> automatically (no extra secret needed)</li> <li>Site URL: https://ejsang.github.io/erik-sangeorzan-portfolio-harman/</li> </ul>"},{"location":"resume-cover/","title":"Resume &amp; Cover Letter","text":"<p>For HARMAN Principal Engineer, Audio Systems Role</p> <p>Last updated: 2026-02-15</p>"},{"location":"resume-cover/#resume","title":"Resume","text":"<p> Open in Google Docs   |   Download PDF </p>"},{"location":"resume-cover/#cover-letter-harman-principal-engineer","title":"Cover Letter: HARMAN Principal Engineer","text":"<p> Open in Google Docs   |   Download PDF </p>"},{"location":"role-fit/","title":"Role Fit: HARMAN Principal Engineer, Audio Systems","text":"<p>Context: This page maps HARMAN's Principal Engineer requirements to specific project evidence in this portfolio. Each section corresponds to a key requirement from the job description.</p> <p>Professional Experience Note: My professional experience at Ford involved rigorous embedded systems testing, including protocol conformance testing, packet analysis, and deterministic CI test harnesses. This experience complements the hands-on embedded work demonstrated in these projects.</p>"},{"location":"role-fit/#8-years-experience-in-automotive-electronic-product-development-audio-preferred","title":"8+ years' experience in automotive electronic product development (Audio preferred)","text":"<p>Projects: - Toyota Auto-Validation (HARMAN): Direct automotive validation experience demonstrating system-level testing and automated reporting for embedded automotive systems. - Real-Time Audio Separation: Low-latency embedded audio capture and processing\u2014core to automotive infotainment systems.</p>"},{"location":"role-fit/#digital-signal-processing-dsp-signal-flow-design-digital-filtering","title":"Digital Signal Processing (DSP), signal flow design, digital filtering","text":"<ul> <li>Analyzing Tennis Matches Based on Audio: MATLAB-based DSP algorithm development including spectral analysis, transient detection, and frequency response design.</li> <li>Stratum Synthesizer: Assembly-level audio engine demonstrating deep knowledge of signal path and audio processing constraints.</li> <li>Real-Time Audio Separation: I2S/TDM-style audio capture with real-time processing on embedded hardware.</li> </ul>"},{"location":"role-fit/#audioacoustic-systems-and-audio-quality","title":"Audio/acoustic systems and audio quality","text":"<ul> <li>Real-Time Audio Separation: Multi-channel audio processing with understanding of signal fidelity and real-time constraints.</li> <li>Stratum Synthesizer: Direct hardware-level audio synthesis and speaker driver implementation.</li> <li>Analyzing Tennis Matches (Audio DSP): Audio signal quality analysis and algorithm prototyping.</li> </ul>"},{"location":"role-fit/#embedded-system-issues-real-time-debugging-and-integration","title":"Embedded system issues, real-time debugging, and integration","text":"<ul> <li>Zumo Shield Robot: Real-time embedded control with hardware timers, interrupts, and PWM on STM32 microcontroller.</li> <li>Stratum Synthesizer: Low-level debugging of hardware interfaces (speaker, SD card, touchscreen) and integration of multiple peripherals.</li> <li>Real-Time Audio Separation: Multi-processor integration (Teensy + Raspberry Pi), I2S and UART interface management, and embedded Linux integration.</li> </ul>"},{"location":"role-fit/#audio-interfaces-i2stdm-audio-drivers-fixed-point-and-floating-point-processing","title":"Audio interfaces (I2S/TDM), audio drivers, fixed-point and floating-point processing","text":"<ul> <li>Real-Time Audio Separation: I2S audio capture with Teensy firmware and UART streaming; demonstrates embedded audio streaming and interface management.</li> <li>Stratum Synthesizer: Low-level peripheral drivers including speaker control and SD card interface.</li> </ul>"},{"location":"role-fit/#vehicle-networking-can-most-diagnostics-uds-kwp2000-and-system-integration","title":"Vehicle networking (CAN, MOST), diagnostics (UDS, KWP2000), and system integration","text":"<ul> <li>Professional: Ford experience with embedded systems and protocol conformance testing provides grounding in automotive communication principles.</li> <li>Toyota Auto-Validation: System-level validation approach demonstrates understanding of integration and verification across components.</li> </ul>"},{"location":"role-fit/#problem-solving-communication-and-technical-specification-management","title":"Problem solving, communication, and technical specification management","text":"<ul> <li>Toyota Auto-Validation: Test automation and reporting framework showing ability to communicate technical results to stakeholders.</li> <li>Projects: Each project includes comprehensive documentation, design rationale, and code explanations showing attention to clarity and communication.</li> <li>Process: I estimate, organize, and document tasks as part of standard engineering practice.</li> </ul>"},{"location":"role-fit/#cc-proficiency-and-embedded-software-development","title":"C/C++ proficiency and embedded software development","text":"<ul> <li>Real-Time Audio Separation: Teensy C++ firmware and Python processing demonstrations.</li> <li>Stratum Synthesizer: Assembly and C-level driver implementation.</li> <li>Zumo Shield Robot: Embedded C for microcontroller control.</li> <li>Toyota Auto-Validation: C# automation framework demonstrating language versatility.</li> </ul>"},{"location":"role-fit/#hardware-debugging-with-instruments-and-embedded-tools","title":"Hardware debugging with instruments and embedded tools","text":"<ul> <li>Zumo Shield Robot and Stratum Synthesizer: Hardware bring-up and telemetry demonstrate use of debugging workflows with hardware interfaces.</li> <li>Real-Time Audio Separation: Integration of multiple embedded platforms with careful interface validation.</li> </ul>"},{"location":"projects/","title":"Projects","text":"<p>Browse the projects below. Each card links to a detailed page with context, design notes, and selected code.</p> <ul> <li>Real-Time Audio Separation of Human Voices: Real-time multitasking audio acquisition (Teensy + Raspberry Pi), I2S, UART, and embedded Linux multiprocessing.</li> <li>Stratum Synthesizer (Assembly): Low-level drivers (speaker, SD, touchscreen) and audio synthesis implemented in assembly for constrained systems.</li> <li>Zumo Shield Robot Navigation (C): Embedded C navigation and control with PWM motor control, hardware timers, and UART telemetry.</li> <li>Toyota Auto-Validation (HARMAN) Demo: Validation and test automation demo for system-level testing and automated reporting.</li> <li>Analyzing Tennis Matches Based on Audio (MATLAB): DSP algorithm prototyping and signal processing.</li> </ul>"},{"location":"projects/real-time-audio-separation/","title":"Real-Time Audio Separation","text":"<pre><code># Real-Time Audio Separation of Human Voices\n\n**Summary:** Real-time source separation project combining embedded Teensy audio acquisition (I2S), UART streaming, Raspberry Pi multicore processing, and a Python GUI for real-time playback and visualization. Demonstrates embedded audio capture, DSP algorithms, synchronization, and performance engineering.\n\n**Problem:** Build a small-form-factor array to capture and separate human voices in real-time.\n\n**Approach:** Implement low-latency audio capture on Teensy (I2S), transmit via UART to a Raspberry Pi, perform online ICA/FFT-based processing with multiprocessing, and provide a multithreaded Python GUI for playback/visualization.\n\n**Results:** Working demo with real-time playback, written report and poster, performance tradeoffs documented.\n\n---\n\n### Skills demonstrated\n\n- C/C++ on embedded platforms (I2S, UART), Python multiprocessing and multithreading\n- Real-time DSP (FFT, ICA), FIR filtering (low-pass)\n- Hardware synchronization using GPIO, performance tuning and profiling\n\n### Why this is relevant to HARMAN\n\n- **I2S/TDM Audio Capture**: Direct experience with I2S audio streaming, the core interface for automotive audio systems.\n- **Embedded DSP**: Real-time FFT and ICA processing on constrained hardware mirrors work needed for audio processing in in-vehicle infotainment.\n- **Real-time Multitasking**: Managed multiprocessing/multithreading with strict latency and synchronization constraints.\n- **System Integration**: Integrated multiple embedded platforms with careful timing and interface validation.\n\n### How to run / reproduce\n\nHardware:\n\n- Teensy boards with Audio Shield (or equivalent), a Raspberry Pi (4 recommended), microphones (or test audio), and a UART connection between Teensy and Pi.\n\nQuick steps:\n\n- Run the self-contained demo: open `src_computer_runnable_demo/` and follow its README.\n- On the Raspberry Pi (or laptop):\n  - Create a Python virtualenv and install dependencies: `pip install numpy scipy matplotlib pyaudio`\n  - Run:\n\n```bash\npython3 src/multiproc_cogent.py\npython3 src/ui3_1_maxplayback.py\n```\n\n- On each Teensy: flash `src/valuecheck.ino` (use Arduino IDE / Teensy Loader) and set I2S/UART parameters as described in `OVERVIEW.txt`.\n\n### What I'd improve next\n\n- **Latency Budget**: Quantify and optimize the end-to-end latency budget (currently limited by UART bandwidth).\n- **Buffering Strategy**: Implement circular buffering to reduce jitter and dropouts.\n- **Test Strategy**: Add automated regression tests for the DSP blocks.\n\n### Downloads\n\n- [Final report (PDF)](../assets/real-time-audio-separation/2021-Team-2-final.pdf){:target=\"_blank\"}\n- [Slide deck (PDF)](../assets/real-time-audio-separation/2021-Team-2-slides.pdf){:target=\"_blank\"}\n- [Poster (PDF)](../assets/real-time-audio-separation/2021-Team-2-poster.pdf){:target=\"_blank\"}\n- [Demo video (MP4)](../assets/real-time-audio-separation/slide10_video1_final_demo.mp4){:target=\"_blank\"}\n- [Runnable demo (zip)](../assets/real-time-audio-separation/real-time-demo.zip){:target=\"_blank\"}\n\n### What to inspect\n\n- See the **Final report** for design decisions, synchronization approach, and performance analysis.\n- Play the **Demo video** for the live system behavior and slide commentary.\n- Download the **Runnable demo** to run the self-contained demo locally (instructions in `USAGE.txt`).\n- Inspect `src/valuecheck.ino` for Teensy I2S/UART firmware and `src/multiproc_cogent.py` for the Python multiprocessing implementation.\n</code></pre>"},{"location":"projects/stratum-synthesizer/","title":"Stratum Synthesizer","text":"<pre><code># Stratum Synthesizer (Assembly)\n\n**Summary:** A hand-crafted audio synthesizer implemented largely in assembly with low-level drivers for speaker output, SD card access, SDRAM, and touchscreen I/O - focused on efficiency and driver-level control.\n\n**Problem:** Produce a functional synthesizer on constrained embedded hardware with multiple instrument voices and low-latency control.\n\n**Approach:** Implement synthesis routines and driver code in assembly for tight control over timing and memory; build drivers for SD I/O and speaker output.\n\n**Results:** Full synthesizer with multiple instruments and a touchscreen interface; source demonstrates low-level driver work and audio path implementation.\n\n---\n\n### Skills demonstrated\n\n- Assembly-level optimization and hardware driver development\n- Real-time audio signal generation and low-latency control\n- Debugging constrained systems and interfacing with peripherals\n\n### Why this is relevant to HARMAN\n\n- Shows deep expertise in low-level embedded audio engineering: driver development for audio hardware (speaker output, peripheral interfaces), real-time constraints, and efficient use of constrained memory.\n- Demonstrates understanding of audio signal path from synthesis through hardware interface\u2014critical for automotive audio systems.\n\n### Driver Interface Sketch\n\n```c\n// Pseudocode illustrating the driver interface logic implemented in assembly\n// See 'speaker_driver.e' for the actual assembly implementation\n\nvoid Audio_ISR(void) {\n    // 1. Acknowledge Interrupt\n    Clear_IRQ(AUDIO_IRQ_MASK);\n\n    // 2. Check FIFO status\n    if (!FIFO_Full(AUDIO_FIFO_ADDR)) {\n        // 3. Fetch next sample from synthesis engine\n        int16_t sample = Synth_GetNextSample();\n\n        // 4. Write to hardware register\n        Write_Reg(AUDIO_DATA_REG, sample);\n    }\n}\n```\n\n### How to run / reproduce\n\n- **Target Hardware:** Nios II soft-core processor on DE1-SoC FPGA (Altera).\n- **Toolchain:** See `Stratum Written Report.pdf` for details. The project was built and tested on the original target hardware.\n- To run on target hardware:\n  - Copy `combined.raw` to the root of an SD card used by the target board.\n  - Load `test_top.e` (or `test_GUI.e` for interactive tests) as the main program using the course toolchain/toolchain loader.\n\n### Downloads\n\n- [Stratum Written Report (PDF)](../assets/stratum-synthesizer/Stratum Written Report.pdf){:target=\"_blank\"}\n- [Presentation (PPTX)](../assets/stratum-synthesizer/Stratum Presentation (download to avoid format issues).pptx){:target=\"_blank\"}\n- [Code (zip)](../assets/stratum-synthesizer/stratum-code.zip){:target=\"_blank\"}\n\n### What to inspect\n\n- Read the **Stratum Written Report** for architecture and driver design notes.\n- Inspect `speaker_driver.e`, `sd_read_driver.e`, and the `synth` modules inside the code zip to see low-level driver logic and instrument synthesis routines.\n</code></pre>"},{"location":"projects/tennis-audio-analysis/","title":"Analyzing Tennis Matches (MATLAB)","text":"<pre><code># Analyzing Tennis Matches Based on Audio (MATLAB)\n\n**Summary:** A signal processing project using MATLAB to analyze audio from tennis matches to detect ball hits, identify \"out\" calls vs. applause, and track game score automatically.\n\n**Problem:** Automate the tracking of tennis match events and scoring using only audio cues.\n\n**Approach:** Developed MATLAB algorithms to detect transients (ball hits), spectral features for applause vs. net hits, and implemented a state machine to track scoring.\n\n**Results:** Successfully detected ball hits and applause in test clips; identified limitations in net hit detection for specific rallies.\n\n---\n\n### Skills demonstrated\n\n- Audio Signal Processing (MATLAB)\n- Algorithm Development (transient detection, spectral analysis)\n- State Machine Logic for scoring\n\n### Why this is relevant to HARMAN\n\n- Demonstrates core DSP algorithm development: transient detection, spectral analysis, and feature extraction\u2014skills directly transferable to automotive audio processing systems.\n- Shows experience in prototyping audio signal processing algorithms before implementation.\n\n### Project website\n\nFor a detailed breakdown of the methodology and results, visit the **[project website](https://ejsang.wixsite.com/eecs351project){:target=\"_blank\"}**.\n\n### Limitations &amp; Fix Plan\n\n- **Limitation:** The current algorithm misses a net hit in Rally 4, causing a scoring drift in subsequent events.\n- **Fix Plan:** Implement a stricter spectral template match for \"net hits\" to distinguish them from similar short-duration transients.\n- **Verification:** Add unit tests with synthetic \"net hit\" audio clips to verify detection thresholding.\n\n### How to run / reproduce\n\n- Requirements: MATLAB.\n- Run `main.m` in MATLAB.\n- The script analyzes the audio, prints the game score to the console, and generates plots for detected events.\n\n### Downloads\n\n- [Code (zip)](../assets/tennis-audio-analysis/tennis-audio-code.zip){:target=\"_blank\"}\n\n### What to inspect\n\n- Check `findBallHit.m` to see the transient detection logic.\n- See `main.m` for the integration of detection algorithms into the game loop.\n</code></pre>"},{"location":"projects/toyota-auto-validation/","title":"Toyota Auto-Validation (HARMAN) Demo","text":"<p>Summary: Automated validation demo for embedded automotive systems, showcasing programmatic control of test equipment and data-driven testing scenarios using C# scripts.</p> <p>Problem: Demonstrate automated validation and reporting for an embedded automotive system.</p> <p>Approach: - Developed C# validation scripts to automate system-level test scenarios. - Implemented programmatic control of lab equipment (function generators) to simulate input signals. - Automated parameter updates for variable test conditions (e.g., specific data sets, frequency response scenarios like <code>DAB Stereo: Speed, -30dB, 80mph</code>).</p> <p>Results: Demo video and notes showcasing test methodology and results.</p>"},{"location":"projects/toyota-auto-validation/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>Test Automation: Equipment control API implementation and test case parameterization.</li> <li>Reporting: Automated generation of validation results and reports.</li> <li>Verification: System-level validation mindset and stakeholder communication.</li> </ul>"},{"location":"projects/toyota-auto-validation/#why-this-is-relevant-to-harman","title":"Why this is relevant to HARMAN","text":"<ul> <li>Directly demonstrates automotive embedded system validation experience for complex system-level testing and verification.</li> <li>Shows ability to design and implement automated test frameworks that scale with product complexity.</li> <li>Illustrates communication of technical validation results to stakeholders and project teams.</li> </ul>"},{"location":"projects/toyota-auto-validation/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Play the demo video below to view the validation walkthrough.</li> </ul>"},{"location":"projects/toyota-auto-validation/#downloads-video","title":"Downloads &amp; video","text":"<ul> <li>Demo video: toyota-demo.mp4</li> <li>Code snippet: validation_snippet.cs (Sample abstraction for equipment control)</li> </ul>"},{"location":"projects/toyota-auto-validation/#what-to-inspect","title":"What to inspect","text":"<ul> <li>Watch the Demo video to see the automated test setup and equipment control in action.</li> <li>Review the Code snippet for an example of the driver/control abstraction used for test automation.</li> </ul>"},{"location":"projects/zumo-shield-robot/","title":"Zumo Shield Robot","text":"<pre><code># Zumo Shield Robot Navigation (C)\n\n**Summary:** STM32-based robot navigation project showing motor control, sensor IO, PWM, timers, and UART telemetry using the STM32 HAL and C.\n\n**Problem:** Implement reliable line-following and navigation on a Zumo robot using the STM32 microcontroller.\n\n**Approach:** Use STM32 HAL to manage PWM motor control, GPIO sensors, timers and UART for debug telemetry; implement sensor scanning and corrective control logic in C.\n\n**Results:** Working line-following implementation with telemetry and documented firmware (`main.c`).\n\n---\n\n### Skills demonstrated\n\n- Embedded C programming on STM32 (PWM, timers, UART, GPIO)\n- Low-level hardware control and real-time loop design for control systems\n- Hardware debugging and interfacing with sensors and actuators\n\n### Why this is relevant to HARMAN\n\n- Demonstrates embedded firmware development fundamentals: hardware driver usage, PWM/timing control, and real-time control loops\u2014all essential for automotive embedded systems.\n- UART telemetry debugging and hardware profiling skills transfer directly to embedded audio systems development.\n\n### Test Procedure\n\n1. **Unit Test:** Verify individual sensor readings via UART output while manually moving the robot over contrasting surfaces.\n2. **Integration Test:** Tune PID control loop parameters (Kp, Ki, Kd) using real-time telemetry to achieve stable line tracking at increasing speeds.\n3. **System Validation:** Run full course navigation tests to verify corner handling and intersection logic.\n\n### How to run / reproduce\n\n- Open the `Line follower` project in STM32CubeIDE (the project was created with STM32 Cube tools).\n- Build and flash the firmware to the STM32 (Zumo) board.\n- Open a serial console to the board (LPUART1 at 115200 baud) to view `printf` telemetry and debug messages.\n- Verify motor and sensor wiring matches pins in `main.c`; adjust PWM/drive parameters as needed and test in a controlled environment.\n\n### Downloads &amp; presentation video\n\n- [Line follower code (zip)](../assets/zumo-shield-robot/zumo-line-follower.zip){:target=\"_blank\"}\n- **[Presentation video](https://youtu.be/iPAF4b1J8Rs){:target=\"_blank\"}**\n\n### What to inspect\n\n- Open `main.c` in the zip and inspect the sensor scan and correction logic; this is where hardware timing and PWM control are implemented.\n</code></pre>"}]}